{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Optimizing model with Automatic gradient descent\n",
    "\n",
    "import torch \n",
    "\n",
    "## f = w * x\n",
    "## f = 2 *x\n",
    "\n",
    "X = torch.tensor([1,2,3,4],dtype =torch.float32)\n",
    "Y = torch.tensor([2,4,6,8],dtype = torch.float32)\n",
    "w = torch.tensor(0.0,dtype = torch.float32, requires_grad=True)\n",
    "### Model prediction \n",
    "def forward (x):\n",
    "    return w*x\n",
    "## Model loss :MSE\n",
    "def loss(y,y_prediction):\n",
    "\n",
    "    return ((y-y_prediction)**2).mean()\n",
    "\n",
    "## Model gradient \n",
    "\n",
    "def gradient(x,y,y_prediction):\n",
    "    return torch.dot(2*x , y_prediction-y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " number of epochs : 0,w :1.999996, loss:0.000000 \n",
      " number of epochs : 1,w :1.999997, loss:0.000000 \n",
      " number of epochs : 2,w :1.999997, loss:0.000000 \n",
      " number of epochs : 3,w :1.999998, loss:0.000000 \n",
      " number of epochs : 4,w :1.999998, loss:0.000000 \n",
      " number of epochs : 5,w :1.999998, loss:0.000000 \n",
      " number of epochs : 6,w :1.999999, loss:0.000000 \n",
      " number of epochs : 7,w :1.999999, loss:0.000000 \n",
      " number of epochs : 8,w :1.999999, loss:0.000000 \n",
      " number of epochs : 9,w :1.999999, loss:0.000000 \n",
      " number of epochs : 10,w :1.999999, loss:0.000000 \n",
      " number of epochs : 11,w :1.999999, loss:0.000000 \n",
      " number of epochs : 12,w :2.000000, loss:0.000000 \n",
      " number of epochs : 13,w :2.000000, loss:0.000000 \n",
      " number of epochs : 14,w :2.000000, loss:0.000000 \n",
      " number of epochs : 15,w :2.000000, loss:0.000000 \n",
      " number of epochs : 16,w :2.000000, loss:0.000000 \n",
      " number of epochs : 17,w :2.000000, loss:0.000000 \n",
      " number of epochs : 18,w :2.000000, loss:0.000000 \n",
      " number of epochs : 19,w :2.000000, loss:0.000000 \n",
      " number of epochs : 20,w :2.000000, loss:0.000000 \n",
      " number of epochs : 21,w :2.000000, loss:0.000000 \n",
      " number of epochs : 22,w :2.000000, loss:0.000000 \n",
      " number of epochs : 23,w :2.000000, loss:0.000000 \n",
      " number of epochs : 24,w :2.000000, loss:0.000000 \n",
      " number of epochs : 25,w :2.000000, loss:0.000000 \n",
      " number of epochs : 26,w :2.000000, loss:0.000000 \n",
      " number of epochs : 27,w :2.000000, loss:0.000000 \n",
      " number of epochs : 28,w :2.000000, loss:0.000000 \n",
      " number of epochs : 29,w :2.000000, loss:0.000000 \n",
      " number of epochs : 30,w :2.000000, loss:0.000000 \n",
      " number of epochs : 31,w :2.000000, loss:0.000000 \n",
      " number of epochs : 32,w :2.000000, loss:0.000000 \n",
      " number of epochs : 33,w :2.000000, loss:0.000000 \n",
      " number of epochs : 34,w :2.000000, loss:0.000000 \n",
      " number of epochs : 35,w :2.000000, loss:0.000000 \n",
      " number of epochs : 36,w :2.000000, loss:0.000000 \n",
      " number of epochs : 37,w :2.000000, loss:0.000000 \n",
      " number of epochs : 38,w :2.000000, loss:0.000000 \n",
      " number of epochs : 39,w :2.000000, loss:0.000000 \n",
      " number of epochs : 40,w :2.000000, loss:0.000000 \n",
      " number of epochs : 41,w :2.000000, loss:0.000000 \n",
      " number of epochs : 42,w :2.000000, loss:0.000000 \n",
      " number of epochs : 43,w :2.000000, loss:0.000000 \n",
      " number of epochs : 44,w :2.000000, loss:0.000000 \n",
      " number of epochs : 45,w :2.000000, loss:0.000000 \n",
      " number of epochs : 46,w :2.000000, loss:0.000000 \n",
      " number of epochs : 47,w :2.000000, loss:0.000000 \n",
      " number of epochs : 48,w :2.000000, loss:0.000000 \n",
      " number of epochs : 49,w :2.000000, loss:0.000000 \n",
      " number of epochs : 50,w :2.000000, loss:0.000000 \n",
      " number of epochs : 51,w :2.000000, loss:0.000000 \n",
      " number of epochs : 52,w :2.000000, loss:0.000000 \n",
      " number of epochs : 53,w :2.000000, loss:0.000000 \n",
      " number of epochs : 54,w :2.000000, loss:0.000000 \n",
      " number of epochs : 55,w :2.000000, loss:0.000000 \n",
      " number of epochs : 56,w :2.000000, loss:0.000000 \n",
      " number of epochs : 57,w :2.000000, loss:0.000000 \n",
      " number of epochs : 58,w :2.000000, loss:0.000000 \n",
      " number of epochs : 59,w :2.000000, loss:0.000000 \n",
      " number of epochs : 60,w :2.000000, loss:0.000000 \n",
      " number of epochs : 61,w :2.000000, loss:0.000000 \n",
      " number of epochs : 62,w :2.000000, loss:0.000000 \n",
      " number of epochs : 63,w :2.000000, loss:0.000000 \n",
      " number of epochs : 64,w :2.000000, loss:0.000000 \n",
      " number of epochs : 65,w :2.000000, loss:0.000000 \n",
      " number of epochs : 66,w :2.000000, loss:0.000000 \n",
      " number of epochs : 67,w :2.000000, loss:0.000000 \n",
      " number of epochs : 68,w :2.000000, loss:0.000000 \n",
      " number of epochs : 69,w :2.000000, loss:0.000000 \n",
      " number of epochs : 70,w :2.000000, loss:0.000000 \n",
      " number of epochs : 71,w :2.000000, loss:0.000000 \n",
      " number of epochs : 72,w :2.000000, loss:0.000000 \n",
      " number of epochs : 73,w :2.000000, loss:0.000000 \n",
      " number of epochs : 74,w :2.000000, loss:0.000000 \n",
      " number of epochs : 75,w :2.000000, loss:0.000000 \n",
      " number of epochs : 76,w :2.000000, loss:0.000000 \n",
      " number of epochs : 77,w :2.000000, loss:0.000000 \n",
      " number of epochs : 78,w :2.000000, loss:0.000000 \n",
      " number of epochs : 79,w :2.000000, loss:0.000000 \n",
      " number of epochs : 80,w :2.000000, loss:0.000000 \n",
      " number of epochs : 81,w :2.000000, loss:0.000000 \n",
      " number of epochs : 82,w :2.000000, loss:0.000000 \n",
      " number of epochs : 83,w :2.000000, loss:0.000000 \n",
      " number of epochs : 84,w :2.000000, loss:0.000000 \n",
      " number of epochs : 85,w :2.000000, loss:0.000000 \n",
      " number of epochs : 86,w :2.000000, loss:0.000000 \n",
      " number of epochs : 87,w :2.000000, loss:0.000000 \n",
      " number of epochs : 88,w :2.000000, loss:0.000000 \n",
      " number of epochs : 89,w :2.000000, loss:0.000000 \n",
      " number of epochs : 90,w :2.000000, loss:0.000000 \n",
      " number of epochs : 91,w :2.000000, loss:0.000000 \n",
      " number of epochs : 92,w :2.000000, loss:0.000000 \n",
      " number of epochs : 93,w :2.000000, loss:0.000000 \n",
      " number of epochs : 94,w :2.000000, loss:0.000000 \n",
      " number of epochs : 95,w :2.000000, loss:0.000000 \n",
      " number of epochs : 96,w :2.000000, loss:0.000000 \n",
      " number of epochs : 97,w :2.000000, loss:0.000000 \n",
      " number of epochs : 98,w :2.000000, loss:0.000000 \n",
      " number of epochs : 99,w :2.000000, loss:0.000000 \n",
      "Prediction after training f(5) :9.999998092651367\n"
     ]
    }
   ],
   "source": [
    "## Model training \n",
    "## model training paramters :\n",
    "    ### learning_rate = 0.01 \n",
    "    ##  n_iteration = 10 \n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iterations = 100 \n",
    "\n",
    "for epochs in range(n_iterations):\n",
    "\n",
    "    ## prediction \n",
    "    y_pred = forward(X)\n",
    "\n",
    "    ## loss \n",
    "    l = loss(Y,y_pred)\n",
    "\n",
    "    ## gradient \n",
    "\n",
    "   \n",
    "    ## gradient = backward propogtion  \n",
    "    l.backward() ##dl/dw\n",
    "\n",
    "     ## updating the initial weights \n",
    "\n",
    "    with torch.no_grad():\n",
    "        w-=  learning_rate *w.grad\n",
    "\n",
    "\n",
    "    w.grad.zero_()\n",
    "    if epochs %1 == 0:\n",
    "        print(f\" number of epochs : {epochs},w :{w:3f}, loss:{l:8f} \")\n",
    "\n",
    "print(f\"Prediction after training f(5) :{forward(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no epochs :1,w 0.300000, loss:30.000000 \n",
      "no epochs :2,w 0.555000, loss:21.674999 \n",
      "no epochs :3,w 0.771750, loss:15.660188 \n",
      "no epochs :4,w 0.955987, loss:11.314487 \n",
      "no epochs :5,w 1.112589, loss:8.174717 \n",
      "no epochs :6,w 1.245701, loss:5.906232 \n",
      "no epochs :7,w 1.358846, loss:4.267253 \n",
      "no epochs :8,w 1.455019, loss:3.083090 \n",
      "no epochs :9,w 1.536766, loss:2.227532 \n",
      "no epochs :10,w 1.606251, loss:1.609392 \n",
      "no epochs :11,w 1.665314, loss:1.162786 \n",
      "no epochs :12,w 1.715517, loss:0.840112 \n",
      "no epochs :13,w 1.758189, loss:0.606981 \n",
      "no epochs :14,w 1.794461, loss:0.438544 \n",
      "no epochs :15,w 1.825292, loss:0.316848 \n",
      "no epochs :16,w 1.851498, loss:0.228923 \n",
      "no epochs :17,w 1.873773, loss:0.165397 \n",
      "no epochs :18,w 1.892707, loss:0.119499 \n",
      "no epochs :19,w 1.908801, loss:0.086338 \n",
      "no epochs :20,w 1.922481, loss:0.062379 \n",
      "no epochs :21,w 1.934109, loss:0.045069 \n",
      "no epochs :22,w 1.943992, loss:0.032562 \n",
      "no epochs :23,w 1.952394, loss:0.023526 \n",
      "no epochs :24,w 1.959535, loss:0.016998 \n",
      "no epochs :25,w 1.965604, loss:0.012281 \n",
      "no epochs :26,w 1.970764, loss:0.008873 \n",
      "no epochs :27,w 1.975149, loss:0.006411 \n",
      "no epochs :28,w 1.978877, loss:0.004632 \n",
      "no epochs :29,w 1.982045, loss:0.003346 \n",
      "no epochs :30,w 1.984738, loss:0.002418 \n",
      "no epochs :31,w 1.987028, loss:0.001747 \n",
      "no epochs :32,w 1.988973, loss:0.001262 \n",
      "no epochs :33,w 1.990628, loss:0.000912 \n",
      "no epochs :34,w 1.992033, loss:0.000659 \n",
      "no epochs :35,w 1.993228, loss:0.000476 \n",
      "no epochs :36,w 1.994244, loss:0.000344 \n",
      "no epochs :37,w 1.995108, loss:0.000248 \n",
      "no epochs :38,w 1.995841, loss:0.000180 \n",
      "no epochs :39,w 1.996465, loss:0.000130 \n",
      "no epochs :40,w 1.996995, loss:0.000094 \n",
      "no epochs :41,w 1.997446, loss:0.000068 \n",
      "no epochs :42,w 1.997829, loss:0.000049 \n",
      "no epochs :43,w 1.998155, loss:0.000035 \n",
      "no epochs :44,w 1.998432, loss:0.000026 \n",
      "no epochs :45,w 1.998667, loss:0.000018 \n",
      "no epochs :46,w 1.998867, loss:0.000013 \n",
      "no epochs :47,w 1.999037, loss:0.000010 \n",
      "no epochs :48,w 1.999181, loss:0.000007 \n",
      "no epochs :49,w 1.999304, loss:0.000005 \n",
      "no epochs :50,w 1.999408, loss:0.000004 \n",
      "no epochs :51,w 1.999497, loss:0.000003 \n",
      "no epochs :52,w 1.999573, loss:0.000002 \n",
      "no epochs :53,w 1.999637, loss:0.000001 \n",
      "no epochs :54,w 1.999691, loss:0.000001 \n",
      "no epochs :55,w 1.999738, loss:0.000001 \n",
      "no epochs :56,w 1.999777, loss:0.000001 \n",
      "no epochs :57,w 1.999810, loss:0.000000 \n",
      "no epochs :58,w 1.999839, loss:0.000000 \n",
      "no epochs :59,w 1.999863, loss:0.000000 \n",
      "no epochs :60,w 1.999884, loss:0.000000 \n",
      "no epochs :61,w 1.999901, loss:0.000000 \n",
      "no epochs :62,w 1.999916, loss:0.000000 \n",
      "no epochs :63,w 1.999928, loss:0.000000 \n",
      "no epochs :64,w 1.999939, loss:0.000000 \n",
      "no epochs :65,w 1.999948, loss:0.000000 \n",
      "no epochs :66,w 1.999956, loss:0.000000 \n",
      "no epochs :67,w 1.999963, loss:0.000000 \n",
      "no epochs :68,w 1.999968, loss:0.000000 \n",
      "no epochs :69,w 1.999973, loss:0.000000 \n",
      "no epochs :70,w 1.999977, loss:0.000000 \n",
      "no epochs :71,w 1.999980, loss:0.000000 \n",
      "no epochs :72,w 1.999983, loss:0.000000 \n",
      "no epochs :73,w 1.999986, loss:0.000000 \n",
      "no epochs :74,w 1.999988, loss:0.000000 \n",
      "no epochs :75,w 1.999990, loss:0.000000 \n",
      "no epochs :76,w 1.999991, loss:0.000000 \n",
      "no epochs :77,w 1.999993, loss:0.000000 \n",
      "no epochs :78,w 1.999994, loss:0.000000 \n",
      "no epochs :79,w 1.999995, loss:0.000000 \n",
      "no epochs :80,w 1.999996, loss:0.000000 \n",
      "no epochs :81,w 1.999996, loss:0.000000 \n",
      "no epochs :82,w 1.999997, loss:0.000000 \n",
      "no epochs :83,w 1.999997, loss:0.000000 \n",
      "no epochs :84,w 1.999998, loss:0.000000 \n",
      "no epochs :85,w 1.999998, loss:0.000000 \n",
      "no epochs :86,w 1.999998, loss:0.000000 \n",
      "no epochs :87,w 1.999999, loss:0.000000 \n",
      "no epochs :88,w 1.999999, loss:0.000000 \n",
      "no epochs :89,w 1.999999, loss:0.000000 \n",
      "no epochs :90,w 1.999999, loss:0.000000 \n",
      "no epochs :91,w 1.999999, loss:0.000000 \n",
      "no epochs :92,w 1.999999, loss:0.000000 \n",
      "no epochs :93,w 2.000000, loss:0.000000 \n",
      "no epochs :94,w 2.000000, loss:0.000000 \n",
      "no epochs :95,w 2.000000, loss:0.000000 \n",
      "no epochs :96,w 2.000000, loss:0.000000 \n",
      "no epochs :97,w 2.000000, loss:0.000000 \n",
      "no epochs :98,w 2.000000, loss:0.000000 \n",
      "no epochs :99,w 2.000000, loss:0.000000 \n",
      "no epochs :100,w 2.000000, loss:0.000000 \n",
      "prediction after the training f(6) :9.999998 \n"
     ]
    }
   ],
   "source": [
    "## Changing manually computing loss and paramater by  using loss and optimizer classes in pytorch \n",
    "## computing model prediction by using pytorch classes\n",
    "\n",
    "\n",
    "##General training pipline in pytorch \n",
    "  ## 1. Designing the model (input , output_size , forward )\n",
    "  ## 2. Construct the loss and the optimizer \n",
    "  ## 3. Training loop \n",
    "     ##forward pass : compute prediction \n",
    "     ## backward : compute gradient \n",
    "     ## update weights \n",
    "     ## empty the grad\n",
    "        \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "X= torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8],dtype=torch.float32)\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "learning_rate = 0.01\n",
    "### Construct the loss and the optimizer \n",
    "\n",
    "loss =nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w],lr=learning_rate)\n",
    "\n",
    "\n",
    "## Training loop \n",
    "n_iterations : 100 \n",
    "\n",
    "for epochs in range(n_iterations):\n",
    "\n",
    "  ##forward pass \n",
    "  y_pred = forward(X)\n",
    "\n",
    "  ##loss \n",
    "  le = loss(Y,y_pred)\n",
    "\n",
    "  ## backward gradient \n",
    "\n",
    "  le.backward()\n",
    "\n",
    "  ##updating weights \n",
    "\n",
    "  optimizer.step()\n",
    "\n",
    "  ##zero grad\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  \n",
    "  print(f\"no epochs :{epochs +1},w {w:3f}, loss:{le:8f} \")\n",
    "\n",
    "\n",
    "print(f\"prediction after the training f(6) :{forward(5):3f} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before the training f(5) :-0.4485284090042114\n",
      "number of epochs:1,w:<generator object Module.parameters at 0x7f052e9e5b30>,loss :36.10307312011719\n",
      "number of epochs:11,w:<generator object Module.parameters at 0x7f052e9e59e0>,loss :0.9353355169296265\n",
      "number of epochs:21,w:<generator object Module.parameters at 0x7f052e9e5b30>,loss :0.025389131158590317\n",
      "number of epochs:31,w:<generator object Module.parameters at 0x7f052e9e59e0>,loss :0.0017773190047591925\n",
      "number of epochs:41,w:<generator object Module.parameters at 0x7f052e9e5b30>,loss :0.001101204426959157\n",
      "number of epochs:51,w:<generator object Module.parameters at 0x7f052e9e59e0>,loss :0.0010222933487966657\n",
      "number of epochs:61,w:<generator object Module.parameters at 0x7f052e9e5b30>,loss :0.0009624044178053737\n",
      "number of epochs:71,w:<generator object Module.parameters at 0x7f052e9e59e0>,loss :0.0009063722682185471\n",
      "number of epochs:81,w:<generator object Module.parameters at 0x7f052e9e5b30>,loss :0.0008536239620298147\n",
      "number of epochs:91,w:<generator object Module.parameters at 0x7f052e9e59e0>,loss :0.0008039262611418962\n",
      "Prediction after the training f(5):10.047173\n"
     ]
    }
   ],
   "source": [
    "## Changing manually computing loss and paramater by  using loss and optimizer classes in pytorch \n",
    "## computing model prediction by using pytorch classes\n",
    "\n",
    "\n",
    "##General training pipline in pytorch \n",
    "  ## 1. Designing the model (input , output_size , forward )\n",
    "  ## 2. Construct the loss and the optimizer \n",
    "  ## 3. Training loop \n",
    "     ##forward pass : compute prediction \n",
    "     ## backward : compute gradient \n",
    "     ## update weights \n",
    "     ## empty the grad\n",
    "    \n",
    "X= torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
    "Y = torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
    "n_samples , n_features = X.shape\n",
    "X_test = torch.tensor([5],dtype=torch.float32)\n",
    "input_size =n_features\n",
    "output_size = n_features\n",
    "## Designing the model (input , output_size , forward )\n",
    "model = nn.Linear(input_size,output_size)\n",
    "\n",
    "\n",
    "print(f\"Prediction before the training f(5) :{model(X_test).item()}\")\n",
    "\n",
    "\n",
    "##Training loop \n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
    "\n",
    "\n",
    "for epochs in range(n_iters):\n",
    "\n",
    "  ##forward pass \n",
    "  y_pred = model(X)\n",
    "\n",
    "  ## loss \n",
    "  le = loss(y_pred,Y)\n",
    "\n",
    "  ##backward \n",
    "  le.backward()\n",
    "\n",
    "  ##update our weights\n",
    "\n",
    "  optimizer.step()\n",
    "\n",
    "  ##zero grad \n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  if epochs % 10 == 0:\n",
    "    print(f\"number of epochs:{epochs +1},w:{model.parameters()},loss :{le}\")\n",
    "\n",
    "print(f\"Prediction after the training f(5):{model(X_test).item():3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "336d0fd160d94e0e0f6591eaf10611da6cd73f7da6c7ea5a76062720089abcab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
